{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe98659-5cbe-4e46-b7e2-11cabb03d2d5",
   "metadata": {},
   "source": [
    "# Red Teaming AI: Manipulating the Model  \n",
    "\n",
    "## Overview  \n",
    "This project explores how machine learning (ML) models react to changes in input data and training data, highlighting vulnerabilities that arise from data manipulation. By demonstrating real-world attack techniques, we showcase the security risks associated with adversarial ML.  \n",
    "\n",
    "## Vulnerabilities Covered  \n",
    "- **Injection Manipulation (ML01)** – Exploiting model inputs to manipulate predictions.  \n",
    "- **Data Poisoning (ML02)** – Contaminating training data to degrade model integrity.  \n",
    "\n",
    "## Dataset & Code  \n",
    "The dataset and code used in this project are derived from the **Hack The Box AI Red Teaming spam classifier** featured in the *Applications of AI in InfoSec* module.  \n",
    "\n",
    "## Objective  \n",
    "By understanding these ML security risks, researchers and security professionals can develop better defenses against adversarial manipulation, ensuring model robustness and reliability in real-world deployments.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaaa1bc-7873-4783-b6b8-a44ee1791ff7",
   "metadata": {},
   "source": [
    "# Creating the Model to Interact with from HTB's Code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51991776-c523-42cb-a9dc-e5d46f5f1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Required Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba7a7354-0a60-4382-bad7-673d775cd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Helper\n",
    "def preprocess_message(message):\n",
    "    stop_words = set(stopwords.words(\"english\")) - {\"free\", \"win\", \"cash\", \"urgent\"}\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    message = message.lower()\n",
    "    message = re.sub(r\"[^a-z\\s$!]\", \"\", message)\n",
    "    tokens = word_tokenize(message)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df['message'] = df['message'].apply(preprocess_message)\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3ac11be-c4be-437a-9ca6-dd24d8f0e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Helper\n",
    "\n",
    "# classify messages by a trained model\n",
    "def classify_messages(model, msg_df, return_probabilities=False):\n",
    "    if isinstance(msg_df, str):\n",
    "        msg_preprocessed = [preprocess_message(msg_df)]\n",
    "    else:\n",
    "        msg_preprocessed = [preprocess_message(msg) for msg in msg_df]\n",
    "\n",
    "    msg_vectorized = model.named_steps[\"vectorizer\"].transform(msg_preprocessed)\n",
    "\n",
    "    if return_probabilities:\n",
    "        return model.named_steps[\"classifier\"].predict_proba(msg_vectorized)\n",
    "\n",
    "    return model.named_steps[\"classifier\"].predict(msg_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4849ab03-822f-46d6-85f9-5b3102767d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model on the given data set\n",
    "def train(dataset):\n",
    "    # read training data set\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    # data preprocessing\n",
    "    df = preprocess_dataframe(df)\n",
    "\n",
    "    # data preparation\n",
    "    vectorizer = CountVectorizer(min_df=1, max_df=0.9, ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform(df[\"message\"])\n",
    "    y = df[\"label\"].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "\n",
    "    # training\n",
    "    pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"classifier\", MultinomialNB())])\n",
    "    param_grid = {\"classifier__alpha\": [0.1, 0.5, 1.0]}\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"f1\")\n",
    "    grid_search.fit(df[\"message\"], y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e24f98a4-630e-44cb-a737-80c833431913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model on our test dataset\n",
    "def evaluate(model, dataset):\n",
    "    # read test data set\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    # prepare labels\n",
    "    df['label'] = df['label'].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "\n",
    "    # get predictions\n",
    "    predictions = classify_messages(model, df['message'])\n",
    "\n",
    "    # compute accuracy\n",
    "    correct = np.count_nonzero(predictions == df['label'])\n",
    "    return (correct / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af22da-6e99-4d8d-9d4a-17fc695de658",
   "metadata": {},
   "source": [
    "# Manipulating the Input\n",
    "The code contains training and test data in CSV formats. Below we are running the model as expected.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b6e4349-9cc6-4703-b2a7-819008602226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 97.2%\n"
     ]
    }
   ],
   "source": [
    "model = train(\"./redteam_code/train.csv\")\n",
    "acc = evaluate(model, \"./redteam_code/test.csv\")\n",
    "print(f\"Model accuracy: {round(acc*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c2c7b-577c-4889-8094-548f8dc4fb9b",
   "metadata": {},
   "source": [
    "We will adjust the code to print the ouput vulnerabilities for both classes for a given input message. When we run this code we will see the output probabilities from the model, which is a confidence test about the input message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a78aa030-921e-4512-9827-fb2c05882a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Ham\n",
      "Probabilities:\n",
      "\t Ham: 98.93%\n",
      "\tSpam: 1.07%\n"
     ]
    }
   ],
   "source": [
    "model = train(\"./redteam_code/train.csv\")\n",
    "\n",
    "message = \"Hello World! How are you doing?\"\n",
    "\n",
    "predicted_class = classify_messages(model, message)[0]\n",
    "predicted_class_str = \"Ham\" if predicted_class == 0 else \"Spam\"\n",
    "probabilities = classify_messages(model, message, return_probabilities=True)[0]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_str}\")\n",
    "print(\"Probabilities:\")\n",
    "print(f\"\\t Ham: {round(probabilities[0]*100, 2)}%\")\n",
    "print(f\"\\tSpam: {round(probabilities[1]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee3369-bbab-4f92-94cb-793cb2a29740",
   "metadata": {},
   "source": [
    "We can repeat this test with a message that appears like SPAM to test. In any type of input manipulation attack our goal is to trick the model into classifying spam (bad) as ham (good)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "837038c2-c1cf-4828-bf58-d909f21f97a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Spam\n",
      "Probabilities:\n",
      "\t Ham: 0.0%\n",
      "\tSpam: 100.0%\n"
     ]
    }
   ],
   "source": [
    "model = train(\"./redteam_code/train.csv\")\n",
    "\n",
    "message = \"Congratulations! You won a prize. Click here to claim: https://bit.ly/3YCN7PF\"\n",
    "\n",
    "predicted_class = classify_messages(model, message)[0]\n",
    "predicted_class_str = \"Ham\" if predicted_class == 0 else \"Spam\"\n",
    "probabilities = classify_messages(model, message, return_probabilities=True)[0]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_str}\")\n",
    "print(\"Probabilities:\")\n",
    "print(f\"\\t Ham: {round(probabilities[0]*100, 2)}%\")\n",
    "print(f\"\\tSpam: {round(probabilities[1]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca34cc-17b0-4ea9-9857-1e352b17c50f",
   "metadata": {},
   "source": [
    "#### Technique #1: Rephrasing\n",
    "Our goal is to get the victim to click our link and avoid being classified as spam. We need to choose carefully how we can construct a message to bypass the model examination process. We can test to see how our model reacts to words by removing parts of our message and running it by in segments. See below for the response to \"Congratulations!\". \n",
    "\n",
    "This is something we can repeat to construct a dictionary of words that hit a low-rate of spam identification.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80d3f2ab-66b3-4909-95f7-2073820d87ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Spam\n",
      "Probabilities:\n",
      "\t Ham: 35.03%\n",
      "\tSpam: 64.97%\n"
     ]
    }
   ],
   "source": [
    "model = train(\"./redteam_code/train.csv\")\n",
    "\n",
    "message = \"Congratulations!\"\n",
    "\n",
    "predicted_class = classify_messages(model, message)[0]\n",
    "predicted_class_str = \"Ham\" if predicted_class == 0 else \"Spam\"\n",
    "probabilities = classify_messages(model, message, return_probabilities=True)[0]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_str}\")\n",
    "print(\"Probabilities:\")\n",
    "print(f\"\\t Ham: {round(probabilities[0]*100, 2)}%\")\n",
    "print(f\"\\tSpam: {round(probabilities[1]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699dd18-9bde-43cc-808f-2806abdfc3b5",
   "metadata": {},
   "source": [
    "Now we can attempt to circumvent the model's detection by putting together a more elegant message, notice that this reads at 90% (real)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c03315ed-367f-497c-92b3-a2c823a469ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Ham\n",
      "Probabilities:\n",
      "\t Ham: 90.08%\n",
      "\tSpam: 9.92%\n"
     ]
    }
   ],
   "source": [
    "model = train(\"./redteam_code/train.csv\")\n",
    "\n",
    "message = \"Your account has been locked out. You can unlock your account in the next 24h: https://bit.ly/3YCN7PF\"\n",
    "\n",
    "predicted_class = classify_messages(model, message)[0]\n",
    "predicted_class_str = \"Ham\" if predicted_class == 0 else \"Spam\"\n",
    "probabilities = classify_messages(model, message, return_probabilities=True)[0]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_str}\")\n",
    "print(\"Probabilities:\")\n",
    "print(f\"\\t Ham: {round(probabilities[0]*100, 2)}%\")\n",
    "print(f\"\\tSpam: {round(probabilities[1]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591750c9-4ce0-45d4-8201-17eed02bdee6",
   "metadata": {},
   "source": [
    "#### Technique #2: Overpowering\n",
    "You can also take those benign words (not flagged as spam) and add tons of them in order to weight the scale heavier toward a \"HAM\" majority message. That will improve the rating of SPAM vs HAM. This is a way to shadow your intentions from an ML model.\n",
    "\n",
    "Another way to obfuscate this insane message from the user could be to include them in the format of HTML comments or other ways to hide the text in the background but STILL weight this message toward HAM.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a383321-e281-46d7-8f76-1d24521c57e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Ham\n",
      "Probabilities:\n",
      "\t Ham: 100.0%\n",
      "\tSpam: 0.0%\n"
     ]
    }
   ],
   "source": [
    "model = train(\"./redteam_code/train.csv\")\n",
    "\n",
    "message = \"Congratulations! You won a prize. Click here to claim: https://bit.ly/3YCN7PF. But I must explain to you how all this mistaken idea of denouncing pleasure and praising pain was born and I will give you a complete account of the system, and expound the actual teachings of the great explorer of the truth, the master-builder of human happiness.\"\n",
    "predicted_class = classify_messages(model, message)[0]\n",
    "predicted_class_str = \"Ham\" if predicted_class == 0 else \"Spam\"\n",
    "probabilities = classify_messages(model, message, return_probabilities=True)[0]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_str}\")\n",
    "print(\"Probabilities:\")\n",
    "print(f\"\\t Ham: {round(probabilities[0]*100, 2)}%\")\n",
    "print(f\"\\tSpam: {round(probabilities[1]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a22b8-56d8-4ecc-b822-0b1be1920fad",
   "metadata": {},
   "source": [
    "# Manipulating the Training Data\n",
    "I did not manipulate the size of the dataset- I left it alone (be aware if you're doing this by HTB's course, they wanted that).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c112f41a-00f5-4065-b777-f70e3c54c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Ham\n",
      "Probabilities:\n",
      "\t Ham: 98.93%\n",
      "\tSpam: 1.07%\n"
     ]
    }
   ],
   "source": [
    "model = train(\"./redteam_code/train.csv\")\n",
    "\n",
    "message = \"Hello World! How are you doing?\"\n",
    "\n",
    "predicted_class = classify_messages(model, message)[0]\n",
    "predicted_class_str = \"Ham\" if predicted_class == 0 else \"Spam\"\n",
    "probabilities = classify_messages(model, message, return_probabilities=True)[0]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_str}\")\n",
    "print(\"Probabilities:\")\n",
    "print(f\"\\t Ham: {round(probabilities[0]*100, 2)}%\")\n",
    "print(f\"\\tSpam: {round(probabilities[1]*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca415f3-5788-455a-8371-faf4bf26acd1",
   "metadata": {},
   "source": [
    "We can add key words that flag as spam to how the weighting interferes with the outcome. Now we can see below when we add 'spam', it barely influences the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e167313f-70a2-44ee-bbdd-11fd9192d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Ham\n",
      "Probabilities:\n",
      "\t Ham: 96.22%\n",
      "\tSpam: 3.78%\n"
     ]
    }
   ],
   "source": [
    "model = train(\"./redteam_code/train.csv\")\n",
    "\n",
    "message = \"spam,Hello World! How are you doing?\"\n",
    "\n",
    "predicted_class = classify_messages(model, message)[0]\n",
    "predicted_class_str = \"Ham\" if predicted_class == 0 else \"Spam\"\n",
    "probabilities = classify_messages(model, message, return_probabilities=True)[0]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class_str}\")\n",
    "print(\"Probabilities:\")\n",
    "print(f\"\\t Ham: {round(probabilities[0]*100, 2)}%\")\n",
    "print(f\"\\tSpam: {round(probabilities[1]*100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
